<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Supercharge your VLM with Bag-of-Concept Graph to mitigate hallucinations!">
  <meta property="og:title" content="GitHub"/>
  <meta property="og:description" content="GitHub is a hosting platform for open source and private software projects, because it only supports Git as the only version library format for hosting, so the name GitHub."/>
  <meta property="og:url" content="https://ankortn.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="vision language models">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations</title>
  <link rel="icon" type="image/x-icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- 这是给字体输入的库 -->
  <!-- <link href="https://fonts.googleapis.com/css2?family=Pacifico&display=swap" rel="stylesheet"> -->
  <link href="https://fonts.googleapis.com/css2?family=Lobster&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Playwrite+IT+Moderna:wght@100..400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Margarine&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Playwrite+AU+NSW:wght@100..400&display=swap" rel="stylesheet">
  <!-- <link href="https://fonts.googleapis.com/css2?family=Playwrite+IS:wght@100..400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Playwrite+NO:wght@100..400&display=swap" rel="stylesheet"> -->
  <!-- https://fonts.google.com/selection/embed -->
  <style>
    /* .handwriting {
          font-family: 'Lobster', cursive;
      }
    .playwrite-it-moderna {
      font-family: "Playwrite IT Moderna", cursive;
      font-optical-sizing: auto;
      font-style: normal;
    } */
    /* .playwrite-au-nsw {
      font-family: "Playwrite AU NSW", cursive;
      font-optical-sizing: auto;
      font-style: normal;
    } */
    .playwrite-is {
      font-family: "Playwrite IS", cursive;
      font-optical-sizing: auto;
      font-style: normal;
    }
    /* .playwrite-no {
      font-family: "Playwrite NO", cursive;
      font-optical-sizing: auto;
      font-style: normal;
    } */
  </style> 
  <!-- 结尾 -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><img id="painting_icon" width="5%" src="https://cdn.icon-icons.com/icons2/1447/PNG/512/32381bacon_98873.png">BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                  <span class="author-block">
                    Zhantao Yang<sup>1,2,*;</sup>,
                  </span>
                  <span class="author-block">
                    Ruili Feng<sup>2,*;</sup>,
                  </span>
                  <span class="author-block">
                      Keyu Yan<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Huangji Wang<sup>1</sup>,
                  </span>
                  <span class="author-block">
                      Zhicai Wang<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Shangwen Zhu<sup>1</sup>,
                  </span>
                  <span class="author-block">
                      Han Zhang<sup>1,2</sup>,
                  </span>
                  <span class="author-block">
                      Jie Xiao<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Pingyu Wu<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Kai Zhu<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Jixuan Chen<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Chen-Wei Xie<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Chaojie Mao<sup>2</sup>,
                  </span>
                  <span class="author-block">
                      Yue Yang<sup>3</sup>,
                  </span>
                  <span class="author-block">
                      Hongyang Zhang<sup>4</sup>,
                  </span>
                  <span class="author-block">
                      Yu Liu<sup>2</sup>,
                  </span>
                  <span class="author-block">
                    Fan Cheng<sup>1,&#8224;</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Shanghai Jiao Tong University, <sup>2</sup>Alibaba group<br> <sup>3</sup>University of Pennsylvania, <sup>4</sup>University of Waterloo
                      <!-- <br> -->
                      <!-- Conferance name and year -->
                    </span>
                    <span class="eql-cntrb"><small><br>&#8224;<a href="mailto:chengfan@sjtu.edu.cn">chengfan@sjtu.edu.cn</a>, <sup>*</sup><a href="mailto:ztyang196@gmail.com">ztyang196@gmail.com</a>, <sup>*</sup><a href="mailto:ruilifengustc@gmail.com">ruilifengustc@gmail.com</a>, </small></span>
                    
                    <span class="eql-cntrb"><small><br>&#8224;Corresponding author, <sup>*</sup>Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/EMNLP2024_Graph_Caption.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="PleaseEnterHere" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="far fa-images"></i>
                      </span>
                      <span>Demo</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Dataset link -->
              <span class="link-block">
                <a href="Which_dataset" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>

              <!-- Model link -->
              <span class="link-block">
                <a href="readme" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-share-square"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/track_res_output.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>

<section class="section" style="background-color:#efeff081">
  <div class="container is-max-desktop" id="gradio">
    <iframe src="https://www.example.com" width="100%" height="600" frameborder="0" style="border:0; overflow:hidden;"></iframe>
  </div>
</section>
<!-- <section class="section"  style="background-color:#efeff081">
  <div class="container is-max-desktop" id="gradio">
    <gradio-app src="https://llava.hliu.cc"></gradio-app>
  </div>
</section> -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <em>
            This paper presents <strong>Ba</strong>g-of-<strong>Con</strong>cept Graph (<strong>BACON</strong>) to gift models with limited linguistic abilities to taste the privilege of Vision Language Models (VLMs) and reduce hallucinations in the downstream tasks such as detection, visual question answering (VQA), and image generation. Since the visual scenes in physical worlds are structured with complex relations between objects, BACON breaks down annotations into basic minimum elements and presents them in a graph structure. Element-wise style enables easy understanding, and structural composition liberates difficult locating. Careful prompt design births the BACON captions with the help of publicly available VLMs and segmentation methods. In this way, we gather a dataset with 100K annotated images, which endow VLMs with remarkable capabilities, such as accurately generating BACON, transforming prompts into BACON format, envisioning scenarios in the style of BACON, and dynamically modifying elements within BACON through interactive dialogue and more. Wide representative experiments, including detection, VQA, and image generation tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel in their current cutting-edge solutions.
          </em>
          </p>

          <div class="playwrite-is">
            This paper presents <strong>Ba</strong>g-of-<strong>Con</strong>cept Graph (<strong>BACON</strong>) to gift models with limited linguistic abilities to taste the privilege of Vision Language Models (VLMs) and reduce hallucinations in the downstream tasks such as detection, visual question answering (VQA), and image generation. Since the visual scenes in physical worlds are structured with complex relations between objects, BACON breaks down annotations into basic minimum elements and presents them in a graph structure. Element-wise style enables easy understanding, and structural composition liberates difficult locating. Careful prompt design births the BACON captions with the help of publicly available VLMs and segmentation methods. In this way, we gather a dataset with 100K annotated images, which endow VLMs with remarkable capabilities, such as accurately generating BACON, transforming prompts into BACON format, envisioning scenarios in the style of BACON, and dynamically modifying elements within BACON through interactive dialogue and more. Wide representative experiments, including detection, VQA, and image generation tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel in their current cutting-edge solutions.
        </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/1447/PNG/512/32381bacon_98873.png"> BACON: Bag-of-Concept Graph</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified"> 
        <p>BACON provides a representation of an image, including <b>overall description</b>, <b>object list</b>, and <b>relationships</b>.</p>
        <p><b>Method:</b>The construction of BACON representation has two stages, <b>(1) Graph Construction</b> and <b>(2) Graph Grounding</b></p>
        <p>         
          <ul type="1">
            <li><b><span id="graph-construction">Graph Construction</span></b>. </li>
            <ul type="1">
              <li> <b><span id="deconstructingAnnotations">Deconstructing annotations</span></b>: BACON decomposes the annotations of VLMs (GPT-4V here in practice) into basic elements and then combining them according to the specific structure. Based on this approach, we develop the BACON dataset (<a href="#painting_icon">details</a>).</li>
              <div style="text-align: center;">
                <img id="teaser" width="100%" src="static/images/first_image_4.png">     
              </div>
              <li> <b>BACON-Captioner</b>: As an alternative, we fine-tuned a 13B LLaVA model on the BACON dataset to function as a specialized captioner. The trained BACON-Captioner exhibits a high similarity in output distribution to that of GTP-4V. Consequently, BACON-Captioner is a viable alternative and can be used to extend the dataset.</li>
              <div style="text-align: center;">
                <img id="teaser" width="100%" src="static/images/statistic_2.png">     
              </div>
            </ul>  
            <li><b><span id="graph-grounding">Graph Grounding</span></b>. <span style="font-size: 95%;"></li>
              <ul type="1">
                <li><b>1. Get BACON:</b> Derive BACON by <a href="#deconstructingAnnotations">deconstructing annotations</a>;</li>
                For each object in the object list.
                <ul type="1">
                  <li><b>2. Grounding:</b> Using Grounding DINO to obtain candidate regions;</li>
                  <li><b>3. Exclude outrageous answers:</b> Using LLaVA to discard blatant incorrect regions;</li>
                  <li><b>4. Match</b>: Using CLIP to identify the optimal region by comparing the object description with the image in that region..</li>
                </ul>
              </ul>
              <div style="text-align: center;">
                <img id="teaser" width="100%" src="static/images/grounding_dino.png">     
              </div>
          </ul>  
        </p>
      </div>
    </div>
  </div>
</section>





<section class="hero is-small is-light">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/3276/PNG/512/egg_bacon_dish_plate_food_icon_207982.png"> BACON Dataset</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified"> 
        <p>
          To the best of our knowledge, this is the <b>first graph dataset</b> that concurrently offeres <b>open-vocabulary capabilities</b>, <b>detailed object attributes</b>, and <b>comprehensive overall descriptions</b>.
          <!-- <centering>
            <div style="text-align: center;">
              <img id="teaser" width="70%" src="static/images/first_image_1.png">     
            </div>
          </centering> -->    
          <ul type="1">
            <li><b>Training Set</b>. <span style="font-size: 95%;"></li>
            <ul type="1">
              <li> <b>Scale</b>: Refined <b>100k</b> BACON-image pairs. </li>
              <li> <b>Methods</b>: <a href="#graph-construction">graph construction</a> + <a href="#graph-grounding">graph grounding</a></li>
            </ul>  
            <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/train_pipeline_2.png">     
            </div>
            <li><b>Test Benchmark</b>.</li> 
              <ul type="1">
                <li> <b>Scale</b>: <b>4k</b> images, <b>30k</b> objects, and <b>200k</b> relationships. </li>
                <li><b>Detailed methods</b>: </li>
                <ul type="1">
                  <li><b>1. segmentation:</b> Using SAM to detect all objects in an image.</li>
                  <li><b>2. Obtain the object list part:</b> Using VLMs to identify the objects (corrected by human annotation) and then describe each object based on its name (corrected by human annotation).</li>
                  <li><b>3. Obtain the overall description part:</b> Using VLMs to generate the overall description annotation given the object list (corrected by human annotation).</li>
                  <li><b>4. Obtain the relationships part:</b> Using VLMs to determine the relationship between two objects based on their combined masked image (corrected by human annotation).</li>
                </ul>
              </ul> 
              <div style="text-align: center;">
                <img id="teaser" width="100%" src="static/images/test_pipeline_2.png">     
              </div>
          </ul>  
        </p>
      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/3780/PNG/512/factory_robot_manufacturing_industry_robotics_machine_robotic_arm_automation_industrial_production_icon_231898.png"> BACON Capioner</h2>
    </div>
  </div>

<div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified"> 
        <p> 
          <ul type="1">
            <li><b>Interactively Modify BACON with Captioner</b></li> 
            <br>
            <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/edit.png">     
            </div>
            <br>
            <li><b>Distinctive Style of BACON with Prompts</b></li> 
            <br>
            <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/recaption_3.png">     
            </div>
          </ul>  
        </p>
      </div>
    </div>
  </div>

</section>


<section class="hero is-small is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/3310/PNG/512/math_book_school_study_icon_209279.png"> Experiments</h2>
    </div>
  </div>

<div class="container is-max-desktop">
<div class="columns is-centered">
  <div class="column is-full-width">
    <div class="content has-text-justified"> 
      <p>
        With the help of flexibly utilizing desired parts of information and the remarkable capabilities of BACON-Captioner, BACON can be applied to help <b>multiple downstream and direct tasks</b>:    
        <ul type="1">
          <li><b>1. Open-vocabulary Object Detection</b></li>
          <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/1_detection.png">     
          </div>
          <br>
          <li><b>2. Point/Pointing/Video Question Answering (PointQA/PointingQA/VQA)</b></li>  
          <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/3_QA.png">     
          </div>
          <br>
          <li><b>3. Scene Graph Generation</b></li> 

          <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/2_SGG.png">     
          </div>
          <br>

          <!-- <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/first_image_5.png">     
          </div>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/QAs_result.png">     
          </div>
          <br> -->
          <li><b>4. Image Generation</b></li> 
          <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/4_image_generation.png">   
          </div>
          <br>
          <li><b>5. Precision & Recall and User Study</b></li> 
          <br>
          <div style="text-align: center;">
            <img id="teaser" width="100%" src="static/images/5_user.png">   
          </div>
          <br>
      </p>
    </div>
  </div>
</div>
</section>



<section class="hero is-small">
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/1137/PNG/512/1486394979-11-data-visualization_80549.png"> Visualization on Video Captioning</h2>
    </div>
  </div>

<div class="container is-max-desktop">
<div class="columns is-centered">
  <div class="column is-full-width">
    <div class="content has-text-justified"> 
      <p>
            
        <ul type="1">
          <li><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/1146/PNG/512/1486485582-311arrow-film-movie-play-player-start-video_81177.png">BACON on video captioning: <b>Changes at anytime</b></li>
          
          <ul type="1">
            <li><b>Object List</b></li>
            <li><b>Object Color</b></li>
            <li><b>Object Description</b></li>
          </ul>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/video_caption_example_result_3.png">     
            </div>
            <!-- <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/video_caption_example_result_2.png">     
            </div>
            <div style="text-align: center;">
              <img id="teaser" width="100%" src="static/images/video_caption_example_result_1.png">     
            </div> -->
          </centering>
      </p>
    </div>
  </div>
</div>
</section>


<section class="hero is-small is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <br>
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn.icon-icons.com/icons2/4215/PNG/512/analysis_research_example_case_study_icon_262980.png"> Other Examples About BACON</h2>
    </div>
  </div>



  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="content has-text-justified"> 
          <p>
                
            <ul type="1">
              <li><b>Examples of BACON in String Format Obtained by GPT-4V</b></li>
              <br>
                <div style="text-align: center;">
                  <img id="teaser" width="100%" src="static/images/string_example.png">     
                </div>
              <br>
              <li><b>Instruction for GPT-4V to Obtain BACON</b></li>
              <br>
                <div style="text-align: center;">
                  <img id="teaser" width="100%" src="static/images/instruction.png">     
                </div>
              <br>
          </p>
        </div>
      </div>
    </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <br>
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{abc,
          author      = {def},
          title       = {ghi},
          booktitle   = {jkl},
          year        = {nmo}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <br>
    <h2 class="title">Acknowledgement</h2>
    <p>
      This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
             <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
</section>

<!-- 
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
             <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
</html>